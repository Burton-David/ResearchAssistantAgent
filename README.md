ğŸ“š AI-Powered Research Paper Analysis

ğŸš€ Accelerating Scientific Discovery with AI, LangChain, and Vector Databases

 

 

 

ğŸ” Finding high-quality research papers shouldnâ€™t be hard. This project leverages LLMs, LangChain, FAISS vector search, and scientific databases to build an AI-powered research assistant that helps scientists find high-quality citations for research grant applications, literature reviews, and academic exploration.

	ğŸ’¡ Why This Matters?
Researchers spend hours searching for credible citations. This tool automates and enhances the process by ranking papers based on:
		â€¢	Relevance (semantic search via embeddings)
	â€¢	Citation Impact (highly cited papers)
	â€¢	Methodology (identifying strong research techniques)
	â€¢	Recency (fresh papers)
	â€¢	Venue Quality (high-impact journals/conferences)

ğŸš€ Features

âœ… Multi-Source Search: Queries arXiv and Semantic Scholar
âœ… Vector Search: Uses FAISS (with Pinecone support coming soon)
âœ… LLM Analysis: OpenAI embeddings help rank research papers
âœ… Citations & Quality Scoring: Finds the best sources for grant proposals
âœ… Asynchronous Processing: Fast and scalable
âœ… Extensible: Modular design for adding new data sources
âœ… Docker Support: Easy setup with docker-compose

ğŸ“¦ Installation

1ï¸âƒ£ Clone the Repository

git clone https://github.com/Burton-David/ResearchAssistantAgent
cd ResearchAssistantAgent

2ï¸âƒ£ Set Up the Environment

Ensure you have Python 3.8+ installed.

python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows
pip install -r requirements.txt

3ï¸âƒ£ API Key Setup

Youâ€™ll need API keys for Semantic Scholar and OpenAI. Create a .env file in the config/ directory:

mkdir config && touch config/.env

Add the following to .env:

OPENAI_API_KEY=your_openai_key
TAVILY_API_KEY=your_tavily_key
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_key

4ï¸âƒ£ Run the Research Collector

python main.py

ğŸ³ Docker Deployment

For an isolated, ready-to-use setup, run:

docker-compose up --build

This ensures all dependencies, including FAISS, are set up inside a container.

ğŸ› ï¸ How It Works

ğŸ”¹ 1. Collect Papers

papers = await paper_collector.fetch_papers("climate change AI", max_results=50)

	â€¢	Fetches from Semantic Scholar & arXiv
	â€¢	Uses pagination to get full results
	â€¢	Filters for high-quality research

ğŸ”¹ 2. Store in Vector Database

await paper_collector._store_in_vector_db(papers)

	â€¢	Converts papers to embeddings using OpenAI
	â€¢	Stores them in FAISS (local, fast, scalable)

ğŸ”¹ 3. Perform AI-Driven Analysis

results = await analyzer.analyze_research_topic("climate change AI")

	â€¢	Ranks papers based on quality metrics
	â€¢	Uses similarity search to find related papers

ğŸ“ Roadmap

âœ”ï¸ MVP: Fetch papers + basic FAISS search âœ…
ğŸ”œ LangChain Summarization: AI-generated research summaries ğŸ”„
ğŸ”œ Pinecone Support: Scalable cloud-based vector search
ğŸ”œ Full-Text Embeddings: Extract knowledge beyond abstracts
ğŸ”œ Web UI: Interactive dashboard for exploring research

	Got feature ideas? Open an issue or submit a pull request! ğŸš€

ğŸ§‘â€ğŸ’» Contributing

Want to help make research easier? Contributions are welcome!
	1.	Fork this repo
	2.	Create a feature branch (git checkout -b feature-name)
	3.	Commit your changes (git commit -m "Added new feature")
	4.	Push to GitHub (git push origin feature-name)
	5.	Open a pull request

ğŸ“œ License

This project is MIT Licensed â€“ free to use, modify, and contribute.

ğŸš€ Join us in making research faster, smarter, and better.
